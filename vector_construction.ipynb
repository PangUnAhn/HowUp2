{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # For interacting with the operating system (e.g., file paths)\n",
    "import re  # For regular expression operations\n",
    "import pdfplumber  # For extracting text from PDF files\n",
    "from dotenv import load_dotenv  # For loading environment variables from a `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain Core Libraries\n",
    "from langchain.schema import Document  # Document schema for managing structured text data\n",
    "from langchain.embeddings import OpenAIEmbeddings  # Embeddings using OpenAI models\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Text splitting into chunks\n",
    "\n",
    "# LangChain Community Libraries\n",
    "from langchain_community.vectorstores import FAISS  # Vector store for semantic search using FAISS\n",
    "from langchain_core.documents import Document  # Another Document schema (to avoid duplication, remove one)\n",
    "from langchain_core.output_parsers import StrOutputParser  # Converts outputs to strings\n",
    "from langchain_core.runnables import RunnablePassthrough  # Pass-through for inputs in chains\n",
    "from langchain_core.prompts import PromptTemplate  # For creating prompt templates for models\n",
    "\n",
    "# LangChain OpenAI-Specific Libraries\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # OpenAI Embeddings and Chat API wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS Core Libraries\n",
    "from ragas import evaluate  # Main evaluation function for RAGAS\n",
    "from ragas.llms import LangchainLLMWrapper  # Wrapper for LLMs to ensure compatibility with RAGAS\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper  # Wrapper for embeddings compatibility\n",
    "from ragas.testset.generator import TestsetGenerator  # Testset generator for creating question-answer pairs\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, conditional  # Question type strategies\n",
    "from ragas.testset.extractor import KeyphraseExtractor  # Extracts key phrases from documents\n",
    "from ragas.testset.docstore import InMemoryDocumentStore  # Stores documents in memory for fast access\n",
    "from ragas.metrics import answer_relevancy, faithfulness, context_recall, context_precision  # Evaluation metrics\n",
    "\n",
    "from datasets import Dataset  # Hugging Face library for dataset manipulation and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# 🔹 Global Variable Declaration\n",
    "documents = []  # Used as a global list to store all processed document objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Functions Used\n",
    "\n",
    "# 🔹 Function to get a list of files in a folder\n",
    "def get_filenames_in_folder(folder_path):\n",
    "    \"\"\"Returns a list of all file names in the specified folder.\"\"\"\n",
    "    try:\n",
    "        filenames = [file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "        return filenames # Return the list of file names\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "        return []\n",
    "\n",
    "# 🔹 Function to Split PDF Files by Page\n",
    "def chunk_pdf_with_pdfplumber(file_path, start_page=1, end_page=-1):\n",
    "    \"\"\"지정된 페이지 범위에 따라 PDF를 청크로 나누고 이를 Document 객체로 변환합니다.\"\"\"\n",
    "    chunks = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        total_pages = len(pdf.pages)  # Get the total number of pages in the PDF\n",
    "        # Adjust end_page if it is negative\n",
    "        if end_page < 0:\n",
    "            end_page = total_pages + end_page + 1  # Calculate page count from the end\n",
    "        \n",
    "        # Process pages within the specified range\n",
    "        for page_num in range(start_page - 1, end_page):\n",
    "            page = pdf.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                # Clean the text (remove unnecessary characters)\n",
    "                cleaned_text = re.sub(r'\\n|\\r|\\t', ' ', text)  # Remove escape characters\n",
    "                cleaned_text = re.sub(r'표<\\d+-\\d+>', '', cleaned_text)  # Remove '<number-number>' patterns\n",
    "                cleaned_text = re.sub(r'□| |○', '', cleaned_text)  # Remove '□', ' ', '○'\n",
    "                cleaned_text = re.sub(r'<(그림|표) \\d+-\\d+>', '', cleaned_text)  # Remove '<figure number-number>' patterns\n",
    "                \n",
    "                chunks.append({\n",
    "                    \"page_content\": cleaned_text.strip(),\n",
    "                    \"metadata\": {\n",
    "                        \"source_type\": \"pdf\",\n",
    "                        \"file_name\": os.path.basename(file_path),\n",
    "                        \"page_number\": page_num + 1,\n",
    "                        \"doc_id\": f\"{os.path.basename(file_path)}_page_{page_num + 1}\"\n",
    "                    }\n",
    "                })\n",
    "    return chunks\n",
    "\n",
    "# 🔹 Function to Add a New PDF File and Accumulate into Documents (Allow Duplicates)\n",
    "def add_pdf_to_documents(file_path, start_page=1, end_page=-1):\n",
    "    \"\"\"PDF 파일을 읽고 Document 객체로 변환하여 전역 documents 목록에 추가합니다.\"\"\"\n",
    "    global documents  # Use a global variable\n",
    "    chunk_dicts = chunk_pdf_with_pdfplumber(file_path, start_page, end_page)\n",
    "    \n",
    "    # 🔹 Convert each page of the PDF into a Document and append (duplicates allowed)\n",
    "    new_documents = [\n",
    "        Document(page_content=chunk[\"page_content\"], metadata=chunk[\"metadata\"])\n",
    "        for chunk in chunk_dicts\n",
    "    ]\n",
    "    documents.extend(new_documents)  # Append new documents to the existing documents\n",
    "    print(f\"✅ {len(new_documents)}개의 Chunk가 '{file_path}'에서 documents로 추가되었습니다.\")\n",
    "    print(f\"📂 Total documents : {len(documents)}\")\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Add PDF files \n",
    "documents = []  # Reset the document list to remove any leftover data from previous runs.\n",
    "file_list = get_filenames_in_folder('./pdfs')\n",
    "\n",
    "for file in file_list:\n",
    "    file_path = f\"./pdfs/{file}\"\n",
    "    add_pdf_to_documents(file_path, start_page=3, end_page=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Embedding and storing documents in FAISS\n",
    "vectorstore = FAISS.from_documents(documents=documents, embedding=OpenAIEmbeddings())\n",
    "vectorstore.save_local('./db/faiss')\n",
    "print(\"✅ FAISS 데이터베이스가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 RAG-based Test Set Generation Pipeline\n",
    "\n",
    "# Generator\n",
    "generator_llm = ChatOpenAI(model='gpt-4o')  \n",
    "\n",
    "# Critic\n",
    "critic_llm = ChatOpenAI(model='gpt-4o')  \n",
    "\n",
    "# Embedding Model\n",
    "embeddings = OpenAIEmbeddings()  \n",
    "\n",
    "# Wrapper for Embedding Model to Ensure Compatibility with RAGAS\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)  \n",
    "\n",
    "# Model for Creating Keyphrase Extractor (Wrapper for RAGAS Compatibility)\n",
    "langchain_llm = LangchainLLMWrapper(ChatOpenAI(model='gpt-4o'))  \n",
    "\n",
    "# Keyphrase Extractor: Identifies and Extracts Key Information from Documents\n",
    "Keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)  \n",
    "\n",
    "# Chunking and Overlap Configuration for PDF Processing\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)  \n",
    "\n",
    "# In-Memory Document Store Configuration\n",
    "docstore_memory = InMemoryDocumentStore(\n",
    "    splitter=splitter,\n",
    "    embeddings=ragas_embeddings,\n",
    "    extractor=Keyphrase_extractor\n",
    ")\n",
    "\n",
    "# Generator Creation (Generates and Evaluates Simultaneously)\n",
    "# Generator Configuration with Four Components\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm, # Generator\n",
    "    critic_llm, # Critic\n",
    "    ragas_embeddings, # Embedding Model\n",
    "    docstore=docstore_memory # Document Store\n",
    ")\n",
    "\n",
    "# Distribution of Question Types\n",
    "distributions = {\n",
    "    simple: 0.4,  # Questions with a single clear answer\n",
    "    reasoning: 0.2,  # Questions requiring reasoning based on multiple clues\n",
    "    multi_context: 0.2,  # Questions requiring understanding multiple contexts\n",
    "    conditional: 0.2  # Conditional questions, requiring specific conditions\n",
    "}\n",
    "\n",
    "# 🔹 Generate Test Set\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents=documents,  # ✅ Pass the document list\n",
    "    test_size=5,  # Number of question-answer sets to generate\n",
    "    distributions=distributions,  # Difficulty distribution of questions\n",
    "    with_debugging_logs=True,  # Enable debugging logs\n",
    "    raise_exceptions=False  # Do not halt on exceptions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 RAG-Based Question Answering Evaluation Pipeline\n",
    "\n",
    "test_df = testset.to_pandas()\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Prompt Template for Answering Questions\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an AI designed to answer questions using the given context. \n",
    "    Follow these rules strictly:\n",
    "    \n",
    "    1️⃣ **Faithfulness**: \n",
    "       - Provide an answer that is faithful to the context. \n",
    "       - If the answer is not explicitly in the context, respond with 'I don't know.' \n",
    "       - Do not make any assumptions or add information not present in the context.\n",
    "       \n",
    "    2️⃣ **Answer Relevancy**: \n",
    "       - The answer must directly address the question.\n",
    "       - Do not provide unnecessary information.\n",
    "       - Be concise. Answer in 1-2 sentences if possible.\n",
    "       \n",
    "    3️⃣ **Context Usage**: \n",
    "       - Use as much relevant context as necessary to answer the question.\n",
    "       - If possible, list the specific parts of the context you used to generate the answer.\n",
    "       - Avoid using redundant or irrelevant context.\n",
    "    \n",
    "    --- \n",
    "    \n",
    "    # Context: {context}\n",
    "    # Question: {question}\n",
    "    \n",
    "    Provide the answer with the following structure:\n",
    "    \n",
    "    # Short Answer (1 sentence):\n",
    "    # Detailed Explanation (2-3 sentences):\n",
    "    # Supporting Evidence (copy specific phrases from the context that support your answer):\n",
    "    # Used Context (list the specific parts of the context that were used):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# LLM for Question Answering\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# Chain to Handle Context Retrieval, Question Answering, and Output Parsing\n",
    "chain = (\n",
    "    {'context': retriever, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Batch Processing of Questions\n",
    "batch_dataset = []\n",
    "for question in test_dataset['question']:\n",
    "    batch_dataset.append(question)\n",
    "\n",
    "answer = chain.batch(batch_dataset)\n",
    "\n",
    "# Add or Update 'answer' Column in Test Dataset\n",
    "if 'answer' in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns(['answer']).add_column('answer', answer)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column('answer', answer)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=[\n",
    "        context_recall,    # How well the model recalls important context information\n",
    "        faithfulness,      # Factual correctness of the model's answer based on context\n",
    "        answer_relevancy,  # Relevance of the model's answer to the overall question\n",
    "        context_precision  # Precision in using necessary context information\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Convert Evaluation Results to DataFrame\n",
    "result_df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📘 Calculation and output of the average value for each metric\n",
    "average_metrics = result_df.mean(numeric_only=True)  # Calculation of the average for numeric columns\n",
    "print(\"The average value of each metric :\")\n",
    "for metric, avg in average_metrics.items():\n",
    "    print(f\"{metric}: {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
